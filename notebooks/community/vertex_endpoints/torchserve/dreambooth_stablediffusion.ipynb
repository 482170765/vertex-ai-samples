{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18ebbd838e32"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "219f1b1fe8fe"
   },
   "source": [
    "# Deploy and host a Stable Diffusion model on Vertex AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/stable_diffusion/dreambooth_stable_diffusion.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/stable_diffusion/dreambooth_stable_diffusion.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    " <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/stable_diffusion/dreambooth_stable_diffusion.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fce05a8186d6"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to deploy and host a fine-tuned [Stable Diffusion 1.5](https://huggingface.co/runwayml/stable-diffusion-v1-5) model on Vertex AI. For hosting, you use the PyTorch 3 container built for Vertex AI with [TorchServe](https://pytorch.org/serve/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c76216b03fec"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you learn how to host and deploy a Stable Diffusion 1.5 model on Vertex AI.\n",
    "\n",
    "This tutorial uses the following Google Cloud ML services:\n",
    "\n",
    "+ Vertex AI `Model` resource\n",
    "+ Vertex AI `Endpoint` resource\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "+ Create a `torchserve` handler for responding to prediction requests.\n",
    "+ Upload a Stable Diffusion 1.5 model on a prebuilt PyTorch container in Vertex AI.\n",
    "+ Deploy a custom model to a Vertex AI Endpoint.\n",
    "+ Send requests to the endpoint and parse the responses using Vertex AI Prediction service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6deba5a8557"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "This notebook uses a collection of model artifacts fine-tuned to generate images of a small dog. These are the same images used in the original [DreamBooth paper](https://dreambooth.github.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "911dc651ea9c"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI models\n",
    "* Vertex AI endpoints\n",
    "* Vertex AI prediction\n",
    "* Google Cloud Storage\n",
    "* (Optionally) Vertex AI Workbench\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d36bd3d53fa"
   },
   "source": [
    "## Hardware requirements\n",
    "\n",
    "This notebook requires that you use a GPU with a sufficient amount of VRAM available. It was tested on a `Tesla P100-PCIE-16GB` with 16 MiB of VRAM. Run the following cell to ensure that you have the correct hardware configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3dd4022552e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla P100-PCIE-16GB, 16384 MiB, 16280 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=\"csv,noheader\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a782627e5f73"
   },
   "source": [
    "### Create a user-managed notebook on Vertex AI\n",
    "\n",
    "If you are using Vertex AI Workbench, you can create a notebook with the correct configuration by doing the following:\n",
    "\n",
    "+ Go to [Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/workbench/user-managed) in the Google Cloud Console.\n",
    "+ Click **New Notebook** and then click **Python 3 (CUDA Toolkit 11.0)** > **With 1 NVIDIA T4**.\n",
    "+ In the **New notebook** dialog box, click **Advanced Options**. The **Create a user-managed notebook** page opens up.\n",
    "+ In the **Create a user-managed notebook** page, do the following:\n",
    "  * In the **Notebook name** box, type a name for your notebook, for example \"my-stablediffusion-nb\".\n",
    "  * In the **Machine type** drop-down, select **N1-standard** > **n1-standard-16**.\n",
    "  * In the **GPU type** drop-down, select **NVIDIA Tesla P100**.\n",
    "  * Check the box next to **Install NVIDIA GPU driver automatically for me**\n",
    "  * Expand **Disk(s)** and do the following:\n",
    "    - Under **Boot disk type**, select **SSD Persistent Disk**.\n",
    "    - Under **Data disk type**, select **SSD Persistent Disk**.\n",
    "  * Click **Create**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAPoU8Sm5E6e"
   },
   "source": [
    "<div style=\"background:#feefe3; padding:5px; color:#aa0000\">\n",
    "<strong>Caution:</strong> Using a Vertex AI Workbench notebook with the above configuration can increase your costs significantly. You can estimage your costs using the <a href=\"https://cloud.google.com/products/calculator\"><u>costs calculator</u></a>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bb4201cc99a"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the following packages required to execute this notebook.\n",
    "\n",
    "**Note**: You might need to change the version of PyTorch (`torch`) installed by `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9c769df171a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "ftfy\n",
    "google-cloud-aiplatform\n",
    "gradio\n",
    "natsort\n",
    "ninja\n",
    "tensorboard==1.15.0\n",
    "torch\n",
    "torchaudio\n",
    "torchvision\n",
    "torchserve\n",
    "torch-model-archiver\n",
    "torch-workflow-archiver\n",
    "transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e46804ac90d8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (6.1.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.21.0)\n",
      "Requirement already satisfied: gradio in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.17.0)\n",
      "Requirement already satisfied: natsort in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (8.2.0)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.11.1)\n",
      "Requirement already satisfied: tensorboard==1.15.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (1.15.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (0.13.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (0.14.1)\n",
      "Requirement already satisfied: torchserve in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (0.7.0)\n",
      "Requirement already satisfied: torch-model-archiver in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (0.7.0)\n",
      "Requirement already satisfied: torch-workflow-archiver in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (0.2.6)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (4.26.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (1.51.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (1.21.6)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (3.19.6)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (66.1.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard==1.15.0->-r requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from ftfy->-r requirements.txt (line 1)) (0.2.6)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (1.22.2)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (1.8.1)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (1.34.0)\n",
      "Requirement already satisfied: shapely<2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (1.8.5.post1)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: packaging<22.0.0dev,>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform->-r requirements.txt (line 2)) (2.7.0)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (0.20.0)\n",
      "Requirement already satisfied: orjson in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (3.8.5)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (9.4.0)\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (3.17)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (0.3.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (0.89.1)\n",
      "Requirement already satisfied: markdown-it-py[linkify,plugins] in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (0.23.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (1.3.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (3.5.3)\n",
      "Requirement already satisfied: aiofiles in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (22.1.0)\n",
      "Requirement already satisfied: python-multipart in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (0.0.5)\n",
      "Requirement already satisfied: websockets>=10.0 in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (10.4)\n",
      "Requirement already satisfied: markupsafe in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (2.1.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (2.28.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (3.8.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (4.4.0)\n",
      "Requirement already satisfied: altair>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (4.2.2)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (1.10.4)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (0.25.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (6.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (2023.1.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from gradio->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.7/site-packages (from torch->-r requirements.txt (line 7)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch->-r requirements.txt (line 7)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.7/site-packages (from torch->-r requirements.txt (line 7)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch->-r requirements.txt (line 7)) (11.7.99)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torchserve->-r requirements.txt (line 10)) (0.18.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from torchserve->-r requirements.txt (line 10)) (5.9.3)\n",
      "Requirement already satisfied: enum-compat in /opt/conda/lib/python3.7/site-packages (from torch-model-archiver->-r requirements.txt (line 11)) (0.0.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 13)) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 13)) (0.13.2)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 13)) (4.11.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 13)) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 13)) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 13)) (0.12.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 3)) (0.4)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 3)) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.7/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 3)) (4.17.3)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (2.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (1.58.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (1.48.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (2.4.1)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.7/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform->-r requirements.txt (line 2)) (0.12.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers->-r requirements.txt (line 13)) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform->-r requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->gradio->-r requirements.txt (line 3)) (2022.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->gradio->-r requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->gradio->-r requirements.txt (line 3)) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->gradio->-r requirements.txt (line 3)) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->gradio->-r requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio->-r requirements.txt (line 3)) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio->-r requirements.txt (line 3)) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio->-r requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio->-r requirements.txt (line 3)) (4.0.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio->-r requirements.txt (line 3)) (0.13.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio->-r requirements.txt (line 3)) (22.2.0)\n",
      "Requirement already satisfied: starlette==0.22.0 in /opt/conda/lib/python3.7/site-packages (from fastapi->gradio->-r requirements.txt (line 3)) (0.22.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from starlette==0.22.0->fastapi->gradio->-r requirements.txt (line 3)) (3.6.2)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /opt/conda/lib/python3.7/site-packages (from httpx->gradio->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from httpx->gradio->-r requirements.txt (line 3)) (0.16.3)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.7/site-packages (from httpx->gradio->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.7/site-packages (from markdown-it-py[linkify,plugins]->gradio->-r requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py~=1.0 in /opt/conda/lib/python3.7/site-packages (from markdown-it-py[linkify,plugins]->gradio->-r requirements.txt (line 3)) (1.0.3)\n",
      "Requirement already satisfied: mdit-py-plugins in /opt/conda/lib/python3.7/site-packages (from markdown-it-py[linkify,plugins]->gradio->-r requirements.txt (line 3)) (0.3.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio->-r requirements.txt (line 3)) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->gradio->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from uvicorn->gradio->-r requirements.txt (line 3)) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.7/site-packages (from uvicorn->gradio->-r requirements.txt (line 3)) (0.14.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (0.2.8)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 3)) (0.19.3)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 3)) (5.10.2)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 3)) (1.3.10)\n",
      "Requirement already satisfied: uc-micro-py in /opt/conda/lib/python3.7/site-packages (from linkify-it-py~=1.0->markdown-it-py[linkify,plugins]->gradio->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r requirements.txt (line 2)) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58707a750154"
   },
   "source": [
    "### Colab only: Uncomment the following cell to restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77c11549298a"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "294df346a918"
   },
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "### Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "\n",
    "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "\n",
    "3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "### Authenticate your Google Cloud account\n",
    "\n",
    "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ccc9e52986"
   },
   "source": [
    "**1. Vertex AI Workbench**\n",
    "* Do nothing as you are already authenticated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de775a3773ba"
   },
   "source": [
    "**2. Local JupyterLab instance, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "254614fa0c46"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef21552ccea8"
   },
   "source": [
    "**3. Colab, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "603adbbf0532"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6b2ccc891ed"
   },
   "source": [
    "**4. Service account or other**\n",
    "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb5c4ca3e851"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7348591eda51"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/opt/conda/lib/python3.7/site-packages/nvidia/cublas/lib/libcublas.so.11: symbol cublasLtHSHMatmulAlgoInit version libcublasLt.so.11 not defined in file libcublasLt.so.11 with link time reference",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_load_global_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /opt/conda/lib/python3.7/site-packages/torch/lib/../../nvidia/cublas/lib/libcublas.so.11: symbol cublasLtHSHMatmulAlgoInit version libcublasLt.so.11 not defined in file libcublasLt.so.11 with link time reference",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_10042/716427972.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maiplatform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m# See Note [Global dependencies]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_load_global_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'libcublas.so.11'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0m_preload_cuda_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_preload_cuda_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcublas_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcudnn_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /opt/conda/lib/python3.7/site-packages/nvidia/cublas/lib/libcublas.so.11: symbol cublasLtHSHMatmulAlgoInit version libcublasLt.so.11 not defined in file libcublasLt.so.11 with link time reference"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from google.cloud import aiplatform\n",
    "from IPython.display import display\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "from torch import autocast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "697566b5f660"
   },
   "source": [
    "## View model inferences\n",
    "\n",
    "Before uploading the model to Vertex AI, you can review the expected output from the model. The model used in this notebook is available for your use and can be downloaded from Google Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "d63df8d91215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data/vertex-ai/model-deployment/models/stable-diffusion/model.zip...\n",
      "/ [1/1 files][  2.0 GiB/  2.0 GiB] 100% Done  56.9 MiB/s ETA 00:00:00           \n",
      "Operation completed over 1 objects/2.0 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "MODEL_ARTIFACTS = \"model_artifacts\"\n",
    "\n",
    "if not os.path.exists(MODEL_ARTIFACTS):\n",
    "    os.mkdir(MODEL_ARTIFACTS)\n",
    "\n",
    "!gsutil -m cp gs://cloud-samples-data/vertex-ai/model-deployment/models/stable-diffusion/model.zip \\\n",
    "   $MODEL_ARTIFACTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31361bb3366b"
   },
   "source": [
    "### Consolidate model artifacts\n",
    "\n",
    "Once your Stable Diffusion model is done training / fine tuning, you can look at the results! In the next step, you'll need to move the most recent directory of weights for you model into directory with the rest of your model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72920300e016"
   },
   "outputs": [],
   "source": [
    "# @markdown Specify the weights directory to use (leave blank for latest)\n",
    "WEIGHTS_DIR = \"\"  # @param {type:\"string\"}\n",
    "if WEIGHTS_DIR == \"\":\n",
    "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
    "\n",
    "    print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34deceab56f1"
   },
   "outputs": [],
   "source": [
    "!mv {WEIGHTS_DIR}/* {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b23a297295e"
   },
   "source": [
    "Now that you have all of the model artifacts in the same directory, we can create a model checkpoint (.ckpt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5f1227778f8a"
   },
   "outputs": [],
   "source": [
    "# @markdown Run conversion.\n",
    "model_name = \"model-dog\"  # @param {type: \"string\"}\n",
    "ckpt_path = OUTPUT_DIR + f\"/{model_name}.ckpt\"\n",
    "\n",
    "half_arg = \"\"\n",
    "# @markdown  Whether to convert to fp16, takes half the space (2GB), might lose some quality.\n",
    "fp16 = True  # @param {type: \"boolean\"}\n",
    "if fp16:\n",
    "    half_arg = \"--half\"\n",
    "!python convert_diffusers_to_sd.py --model_path $OUTPUT_DIR  --checkpoint_path $ckpt_path $half_arg\n",
    "print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9192ea4f3b57"
   },
   "source": [
    "### Create new images\n",
    "\n",
    "With everying in place, you can now generate new images from the Stable Diffusion model. First you must load your model into a `StableDiffusionPipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd1f30223b79"
   },
   "outputs": [],
   "source": [
    "model_path = \"\"\n",
    "if model_path == \"\":\n",
    "    model_path = OUTPUT_DIR\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_path, torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "g_cuda = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dd91520f58cf"
   },
   "outputs": [],
   "source": [
    "g_cuda = torch.Generator(device=\"cuda\")\n",
    "seed = 52362\n",
    "g_cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e9c5d734b9f"
   },
   "source": [
    "With the model loaded into a `StableDiffusionPipeline`, you can now generate results (inferences) from the model. Each set of inference requires an input (called a [prompt](https://learnprompting.org/)) that specifies what the model should create.\n",
    "\n",
    "You can also vary other inputs into the model, as shown in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a28b73de55ce"
   },
   "outputs": [],
   "source": [
    "prompt = \"photo of examplePup dog with snow mountain background.\"\n",
    "\n",
    "num_samples = 4\n",
    "num_batches = 1\n",
    "num_columns = 2\n",
    "guidance_scale = 10\n",
    "num_inference_steps = 50\n",
    "height = 512\n",
    "width = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11a7bb79de59"
   },
   "outputs": [],
   "source": [
    "def image_grid(imgs, cols):\n",
    "    total = len(imgs)\n",
    "    rows = math.ceil(total / cols)\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    grid_w, grid_h = grid.size\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "all_images = []\n",
    "for _ in range(num_batches):\n",
    "    with autocast(\"cuda\"):\n",
    "        images = pipe(\n",
    "            [prompt] * num_samples,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "        ).images\n",
    "        all_images.extend(images)\n",
    "\n",
    "\n",
    "grid = image_grid(all_images, num_columns)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf8d545a135b"
   },
   "source": [
    "### Re-training the model\n",
    "\n",
    "If you aren't satisfied with the inference outputs from the model, you can retrain it. Before you can do that, you might need to release the GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5621b7a927f8"
   },
   "outputs": [],
   "source": [
    "# Run this cell _only_ if you want to release the GPU memory.\n",
    "pipe = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbc72963ff88"
   },
   "source": [
    "## Deploy the model to Vertex AI\n",
    "\n",
    "You can host your Stable Diffusion 2.0 model on a Vertex AI endpoint where you can get inferences from it online. Uploading your model is a three step process: \n",
    "\n",
    "1. Create a custom TorchServe handler.\n",
    "1. Upload the model artifacts onto Google Cloud Storage.\n",
    "2. Create a Vertex AI model with the model artifacts and a prebuilt PyTorch container image.\n",
    "3. Deploy the Vertex AI model onto an endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67b163c48525"
   },
   "source": [
    "Before we can do that, though, we need to collect all of the model artifacts into a single place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d450d60edf4"
   },
   "outputs": [],
   "source": [
    "!mkdir model_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eafbb0e0-40e6-43a0-a38e-edc54323da51"
   },
   "source": [
    "### Create the custom TorchServe handler\n",
    "\n",
    "The model deployed to Vertex AI uses [TorchServe](https://pytorch.org/serve/) to handle requests and return responses from the model. You must create a custom TorchServe handler to include in with the model artifacts uploaded to Vertex AI.\n",
    "\n",
    "The handler file should be included in the directory with the other model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94567a87-9d74-4c87-a749-306ddaf01b61"
   },
   "outputs": [],
   "source": [
    "%%writefile model_artifacts/handler.py\n",
    "\n",
    "\"\"\"Customized handler for Stable Diffusion 2.\"\"\"\n",
    "import base64\n",
    "import logging\n",
    "from io import BytesIO\n",
    "\n",
    "import torch\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "model_id = 'stabilityai/stable-diffusion-2'\n",
    "\n",
    "\n",
    "class ModelHandler(BaseHandler):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.initialized = False\n",
    "    self.map_location = None\n",
    "    self.device = None\n",
    "    self.use_gpu = True\n",
    "    self.store_avg = True\n",
    "    self.pipe = None\n",
    "\n",
    "  def initialize(self, context):\n",
    "    \"\"\"Initializes the pipe.\"\"\"\n",
    "    properties = context.system_properties\n",
    "    gpu_id = properties.get('gpu_id')\n",
    "\n",
    "    self.map_location, self.device, self.use_gpu = \\\n",
    "      ('cuda', torch.device('cuda:' + str(gpu_id)),\n",
    "       True) if torch.cuda.is_available() else \\\n",
    "        ('cpu', torch.device('cpu'), False)\n",
    "\n",
    "    # Use the Euler scheduler here instead\n",
    "    scheduler = EulerDiscreteScheduler.from_pretrained(model_id,\n",
    "                                                       subfolder='scheduler')\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id,\n",
    "                                                   scheduler=scheduler,\n",
    "                                                   torch_dtype=torch.float16)\n",
    "    pipe = pipe.to('cuda')\n",
    "    # Uncomment the following line to reduce the GPU memory usage.\n",
    "    # pipe.enable_attention_slicing()\n",
    "    self.pipe = pipe\n",
    "\n",
    "    self.initialized = True\n",
    "\n",
    "  def preprocess(self, requests):\n",
    "    \"\"\"Noting to do here.\"\"\"\n",
    "    logger.info('requests: %s', requests)\n",
    "    return requests\n",
    "\n",
    "  def inference(self, preprocessed_data, *args, **kwargs):\n",
    "    \"\"\"Run the inference.\"\"\"\n",
    "    images = []\n",
    "    for pd in preprocessed_data:\n",
    "      prompt = pd['prompt']\n",
    "      images.extend(self.pipe(prompt).images)\n",
    "    return images\n",
    "\n",
    "  def postprocess(self, output_batch):\n",
    "    \"\"\"Converts the images to base64 string.\"\"\"\n",
    "    postprocessed_data = []\n",
    "    for op in output_batch:\n",
    "      fp = BytesIO()\n",
    "      op.save(fp, format='JPEG')\n",
    "      postprocessed_data.append(base64.b64encode(fp.getvalue()).decode('utf-8'))\n",
    "      fp.close()\n",
    "    return postprocessed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ace1dac0af0"
   },
   "source": [
    "After creating the handler file, you must package the handler as a model archiver (MAR) file. The output file must be named 'model.mar'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67707f95d440"
   },
   "outputs": [],
   "source": [
    "!torch-model-archiver \\\n",
    "  -f \\\n",
    "  --model-name model \\\n",
    "  --version 1.0 \\\n",
    "  --handler model_artifacts/handler.py \\\n",
    "  --export-path model_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffab030f4bc8"
   },
   "source": [
    "### Upload the model artifacts to Google Cloud Storage\n",
    "\n",
    "Create a new folder in your Google Cloud Storage bucket to hold the model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://your-bucket-name-unique\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}/\"\n",
    "FULL_GCS_PATH = f\"{BUCKET_URI}model_artifacts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "971232e28657"
   },
   "source": [
    "Next, upload the model archive file and your trained Stable Diffusion 2.0 model to the folder on Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ef6baf44c808"
   },
   "outputs": [],
   "source": [
    "!gsutil cp -r model_artifacts $BUCKET_URI\n",
    "!gsutil cp -r $OUTPUT_DIR $FULL_GCS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "402370ca9396"
   },
   "source": [
    "### Create the Vertex AI model\n",
    "\n",
    "Once you've uploaded the model artifacts into a Cloud Storage bucket, you can create a new Vertex AI model. This notebook uses the [Vertex AI SDK](https://cloud.google.com/vertex-ai/docs/start/use-vertex-ai-python-sdk) to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6c58a74a0fd"
   },
   "outputs": [],
   "source": [
    "PYTORCH_PREDICTION_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/prediction/pytorch-gpu.1-12:latest\"\n",
    ")\n",
    "APP_NAME = \"my-stable-diffusion\"\n",
    "VERSION = 1\n",
    "MODEL_DISPLAY_NAME = \"stable_diffusion_1_4-unique\"\n",
    "MODEL_DESCRIPTION = \"stable_diffusion_1_4 container\"\n",
    "ENDPOINT_DISPLAY_NAME = f\"{APP_NAME}-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07c3503a1a2e"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a776324dd16f"
   },
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    description=MODEL_DESCRIPTION,\n",
    "    serving_container_image_uri=PYTORCH_PREDICTION_IMAGE_URI,\n",
    "    artifact_uri=FULL_GCS_PATH,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fbc3d371574"
   },
   "source": [
    "### Deploy the model to an endpoint\n",
    "\n",
    "To get online preductions from your Stable Diffusion 2.0 model, you must [deploy it to a Vertex AI endpoint](https://cloud.google.com/vertex-ai/docs/predictions/overview). You can again use the Vertex AI SDK to create the endpoint and deploy your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab29f0a770cb"
   },
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.create(display_name=ENDPOINT_DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25f703df88c7"
   },
   "outputs": [],
   "source": [
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=MODEL_DISPLAY_NAME,\n",
    "    machine_type=\"n1-standard-8\",\n",
    "    accelerator_type=\"NVIDIA_TESLA_P100\",\n",
    "    accelerator_count=1,\n",
    "    traffic_percentage=100,\n",
    "    deploy_request_timeout=1200,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9fc560df0a9"
   },
   "source": [
    "If the previous cell times out before returning, your endpoint might still be successfully deployed ot an end point. Check the [Cloud Console](https://console.cloud.google.com/vertex-ai/endpoints) to verify the results.\n",
    "\n",
    "You can also extend the time to wait for deployment by changing the `deploy_request_timeout` argument passed to `model.deploy()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88a5304dfdc9"
   },
   "source": [
    "## Get online predictions\n",
    "\n",
    "Finally, with your Stable Diffusion 2.0 model deployed to a Vertex AI endpoint, you can now get online predictions from it. Using the Vertex AI SDK, you only need a few lines of code to get an inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d6bc4aa34d6"
   },
   "outputs": [],
   "source": [
    "instances = [{\"prompt\": \"An examplePup dog with a baseball jersey.\"}]\n",
    "response = endpoint.predict(instances=instances)\n",
    "\n",
    "with open(\"img5.jpg\", \"wb\") as g:\n",
    "    g.write(base64.b64decode(response.predictions[0]))\n",
    "\n",
    "display.Image(\"img5.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "# Delete endpoint resource\n",
    "endpoint.undeploy_all()\n",
    "endpoint.delete()\n",
    "\n",
    "# Delete model resource\n",
    "\n",
    "model.delete()\n",
    "\n",
    "# Delete Cloud Storage objects that were created\n",
    "delete_bucket = False\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "dreambooth_stablediffusion.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
